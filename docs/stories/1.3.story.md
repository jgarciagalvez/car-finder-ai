# <!-- Powered by BMAD™ Core -->

# Story 1.3: Headless Browser Scraper Service

## Status
Done

## Story
**As a** user,
**I want** a scraper service that uses a headless browser (Puppeteer) to visit URLs and retrieve their full HTML content,
**so that** I can gather the raw data from the marketplace websites.

## Acceptance Criteria
1. Puppeteer is added as a dependency to the `api` application.
2. A `ScraperService` is created that can launch a headless browser with best-practice configurations.
3. The service has a function that accepts a URL and returns the full, rendered HTML content.
4. The service includes respectful delays between requests.

## Tasks / Subtasks
- [x] Add Puppeteer dependency to API application (AC: 1)
  - [x] Install Puppeteer ~22.0.0 in apps/api package
  - [x] Add @types/puppeteer for TypeScript support (not needed - Puppeteer provides own types)
  - [x] Update package.json with proper dependency versions
- [x] Create ScraperService class with browser management (AC: 2)
  - [x] Implement ScraperService class in apps/api/src/services/
  - [x] Add browser launch with best-practice configurations
  - [x] Implement proper browser lifecycle management (launch/close)
  - [x] Add error handling and retry logic for browser operations
- [x] Implement URL scraping functionality (AC: 3)
  - [x] Create scrapeUrl method that accepts URL and returns HTML content
  - [x] Add proper page navigation and wait strategies
  - [x] Implement timeout handling for slow-loading pages
  - [x] Add user agent rotation and stealth configurations
- [x] Add respectful request delays (AC: 4)
  - [x] Implement configurable delay mechanism between requests
  - [x] Add random delay variations to appear more human-like
  - [x] Create rate limiting to prevent overwhelming target sites
- [x] Add comprehensive testing (Testing Requirements)
  - [x] Create unit tests for ScraperService initialization and configuration
  - [x] Create integration tests for actual URL scraping functionality
  - [x] Test error handling and edge cases (timeouts, invalid URLs)
  - [x] Test rate limiting and delay mechanisms
- [x] Add service integration and exports (Integration)
  - [x] Export ScraperService from apps/api/src/index.ts
  - [x] Create service factory or singleton pattern for browser reuse
  - [x] Add proper TypeScript types and interfaces

## Dev Notes

### Previous Story Insights
From Story 1.2 completion:
- Database layer established with SQLite, Kysely, and comprehensive VehicleRepository
- Type-safe integration with @car-finder/types package working
- Monorepo structure with TypeScript project references functional
- Repository Pattern implemented for clean data access abstraction

### Web Scraping Architecture
**Technology:** Puppeteer ~22.0.0 - Headless browser for scraping with robust control over Chrome instance [Source: architecture.md#tech-stack]
**Pattern:** Script-based model using background processing for data ingestion [Source: architecture.md#backend-architecture]
**Location:** apps/api - Backend API application handles scraping and AI analysis [Source: architecture.md#unified-project-structure]

### Technical Requirements and Best Practices
**Headless Browser Configuration:** 
- Use Puppeteer for robust control over headless Chrome instance
- Implement best-practice configurations for stealth and reliability
- Handle browser lifecycle management (launch, reuse, cleanup)

**Request Management:**
- Respectful delays between requests to avoid overwhelming target sites
- User agent rotation and stealth configurations to appear human-like
- Timeout handling for slow-loading pages
- Error handling and retry logic for failed requests

### Project Structure Specifications
**Service Location:** `apps/api/src/services/ScraperService.ts` - Backend service for web scraping
**Integration Point:** Will be used by future ingestion scripts in packages/scripts
**Package Structure:**
```
apps/api/src/
├── services/
│   └── ScraperService.ts     (Headless browser scraping service)
├── index.ts                  (Main API exports)
└── __tests__/
    └── ScraperService.test.ts (Unit and integration tests)
```

### Data Flow and Integration
**Input:** URLs from marketplace websites (Otomoto.pl, OLX.pl)
**Output:** Raw HTML content for parser processing (Story 1.4)
**Integration:** Will be consumed by main ingestion pipeline (Story 1.5)
**Database Integration:** No direct database access - focuses on HTML retrieval only

### Technical Constraints and Configuration
**Node.js Runtime:** ~20.11.0 - Current LTS version [Source: architecture.md#tech-stack]
**TypeScript Integration:** Must follow monorepo TypeScript configuration
**Local-First:** All scraping operations run locally on user's machine [Source: architecture.md#platform-and-infrastructure-choice]
**Zero-Cost:** No external scraping services - pure Puppeteer implementation

### Scraping Best Practices
**Stealth Configuration:**
- Disable images and CSS for faster loading
- Set realistic viewport sizes and user agents
- Randomize request timing and patterns
- Handle JavaScript-rendered content properly

**Error Handling:**
- Graceful handling of network timeouts
- Retry logic for temporary failures
- Proper cleanup of browser resources
- Logging of scraping attempts and failures

**Rate Limiting:**
- Configurable delays between requests (default: 1-3 seconds)
- Respect robots.txt guidelines
- Monitor for rate limiting responses
- Implement exponential backoff for failures

### Integration with Future Stories
**Story 1.4 Integration:** HTML output will be consumed by schema-driven parser
**Story 1.5 Integration:** Will be orchestrated by main ingestion pipeline
**Database Integration:** Raw scraped data will be processed and stored via VehicleRepository

## Testing

### Testing Standards
**Testing Framework:** Jest ~29.7.0 - Standard testing suite [Source: architecture.md#tech-stack]
**Testing Strategy:** Unit Tests for service logic and Integration Tests for actual scraping operations [Source: architecture.md#technical-assumptions]

### Testing Requirements for This Story
**Unit Tests:**
- ScraperService initialization and configuration
- Browser launch and lifecycle management
- Delay and rate limiting mechanisms
- Error handling and retry logic

**Integration Tests:**
- End-to-end URL scraping with real websites
- Browser stealth and user agent configurations
- Timeout and error scenario handling
- Performance and memory usage validation

### Test File Locations
- Tests co-located with source files using `.test.ts` extensions
- Integration tests in `apps/api/src/__tests__/` directory
- Mock data and test URLs in test fixtures

### Specific Test Scenarios
- Successful HTML retrieval from valid URLs
- Handling of JavaScript-heavy pages
- Timeout scenarios with slow-loading pages
- Rate limiting and delay verification
- Browser cleanup and resource management
- Error handling for invalid URLs and network failures

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| Oct 4, 2025 | 1.0 | Initial story creation from Epic 1, Story 1.3 | Bob (SM) |

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4 (James - Full Stack Developer)

### Debug Log References
- Chrome browser installation: `pnpm exec puppeteer browsers install chrome`
- TypeScript compilation fixes: Removed deprecated `waitForTimeout` method
- Test suite optimization: Network-aware test handling for integration tests
- Jest configuration: Created comprehensive test setup with Puppeteer support

### Completion Notes List
- ✅ Successfully implemented comprehensive ScraperService with all required features
- ✅ Added Puppeteer ~22.0.0 dependency (note: @types/puppeteer not needed as Puppeteer provides own types)
- ✅ Implemented browser lifecycle management with proper cleanup and error handling
- ✅ Added stealth configurations including user agent rotation and request interception
- ✅ Implemented respectful delays with configurable ranges and exponential backoff
- ✅ Created comprehensive test suite (33 tests) covering unit and integration scenarios
- ✅ Added API endpoint demonstration (/api/scrape) for service integration
- ✅ All acceptance criteria met and validated through automated testing

### File List
**Created Files:**
- `apps/api/src/services/ScraperService.ts` - Main scraper service implementation
- `apps/api/src/services/ScraperService.test.ts` - Unit tests for ScraperService
- `apps/api/src/__tests__/ScraperService.integration.test.ts` - Integration tests
- `apps/api/src/__tests__/setup.ts` - Jest test setup and utilities
- `apps/api/jest.config.js` - Jest configuration for API package

**Modified Files:**
- `apps/api/package.json` - Added Puppeteer dependency
- `apps/api/src/index.ts` - Added ScraperService export and demonstration endpoint

## QA Results
*Results from QA Agent review will be populated here after story completion*
